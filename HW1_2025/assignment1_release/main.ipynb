{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTv0D26B9W2h"
   },
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qFHMMDtSwuW4"
   },
   "outputs": [],
   "source": [
    "# #@title Mount your Google Drive\n",
    "# # If you run this notebook locally or on a cluster (i.e. not on Google Colab)\n",
    "# # you can delete this cell which is specific to Google Colab. You may also\n",
    "# # change the paths for data/logs in Arguments below.\n",
    "# %matplotlib inline\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oODLwt1QzgGa"
   },
   "outputs": [],
   "source": [
    "# #@title Link your assignment folder & install requirements\n",
    "# #@markdown Enter the path to the assignment folder in your Google Drive\n",
    "# # If you run this notebook locally or on a cluster (i.e. not on Google Colab)\n",
    "# # you can delete this cell which is specific to Google Colab. You may also\n",
    "# # change the paths for data/logs in Arguments below.\n",
    "# import sys\n",
    "# import os\n",
    "# import shutil\n",
    "# import warnings\n",
    "\n",
    "# folder = \"Your path to assignment folder\" #@param {type:\"string\"}\n",
    "# !ln -Ts \"$folder\" /content/assignment 2> /dev/null\n",
    "\n",
    "# # Add the assignment folder to Python path\n",
    "# if '/content/assignment' not in sys.path:\n",
    "#   sys.path.insert(0, '/content/assignment')\n",
    "\n",
    "# # Check if CUDA is available\n",
    "# import torch\n",
    "# if not torch.cuda.is_available():\n",
    "#   warnings.warn('CUDA is not available.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "dt3NTvpsy4Oc",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Running on GPU\n",
    "For this assignment, it will be necessary to run your experiments on GPU. To make sure the notebook is running on GPU, you can change the notebook settings with\n",
    "* (EN) `Edit > Notebook Settings`\n",
    "* (FR) `Modifier > Param√®tres du notebook`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "RLVSmv9HoMH5"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "from torch import optim\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "from utils import seed_experiment, to_device, cross_entropy_loss, compute_accuracy\n",
    "from config import get_config_parser\n",
    "import json\n",
    "from mlp import MLP\n",
    "from resnet18 import ResNet18\n",
    "from mlpmixer import MLPMixer\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZy1J-0OroLg"
   },
   "source": [
    "# Local Test\n",
    "Before run the experiment, here are some local test cases you can run for sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wLEVxwLlroLh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_linear_attributes (test.TestLinear.test_linear_attributes) ... ok\n",
      "test_linear_forward (test.TestLinear.test_linear_forward) ... ok\n",
      "test_activation (test.TestMLP.test_activation) ... ERROR\n",
      "test_forward (test.TestMLP.test_forward) ... ERROR\n",
      "test_mlp (test.TestMLP.test_mlp) ... ERROR\n",
      "test_mixer_block (test.TestMLPMixer.test_mixer_block) ... ok\n",
      "test_mlpmixer (test.TestMLPMixer.test_mlpmixer) ... ERROR\n",
      "test_patch_emb (test.TestMLPMixer.test_patch_emb) ... FAIL\n",
      "test_basic_block (test.TestResNet.test_basic_block) ... ok\n",
      "test_basic_block2 (test.TestResNet.test_basic_block2) ... ERROR\n",
      "test_resnet (test.TestResNet.test_resnet) ... ERROR\n",
      "test_ce_loss (test.TestUtils.test_ce_loss) ... ok\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_activation (test.TestMLP.test_activation)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\maciu\\OneDrive - Universite de Montreal\\Documents\\1-UNIVERSITE DE MONTREAL\\1-COURS\\3- Hiver 2025\\1- IFT6135 - Representation Learning\\3- Devoirs\\HW1_2025\\assignment1_release\\test.py\", line 61, in test_activation\n",
      "    model = MLP(self.input_size, self.hidden_sizes, self.output_size)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\OneDrive - Universite de Montreal\\Documents\\1-UNIVERSITE DE MONTREAL\\1-COURS\\3- Hiver 2025\\1- IFT6135 - Representation Learning\\3- Devoirs\\HW1_2025\\assignment1_release\\mlp.py\", line 50, in __init__\n",
      "    self.hidden_layers, self.output_layer = self._build_layers(self.input_size, self.hidden_sizes, self.num_classes)\n",
      "                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\OneDrive - Universite de Montreal\\Documents\\1-UNIVERSITE DE MONTREAL\\1-COURS\\3- Hiver 2025\\1- IFT6135 - Representation Learning\\3- Devoirs\\HW1_2025\\assignment1_release\\mlp.py\", line 75, in _build_layers\n",
      "    hidden_layers.append(self.activation_fn(self.activation, hidden_layer))\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\OneDrive - Universite de Montreal\\Documents\\1-UNIVERSITE DE MONTREAL\\1-COURS\\3- Hiver 2025\\1- IFT6135 - Representation Learning\\3- Devoirs\\HW1_2025\\assignment1_release\\mlp.py\", line 86, in activation_fn\n",
      "    return activation(inputs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: 'str' object is not callable\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_forward (test.TestMLP.test_forward)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\maciu\\OneDrive - Universite de Montreal\\Documents\\1-UNIVERSITE DE MONTREAL\\1-COURS\\3- Hiver 2025\\1- IFT6135 - Representation Learning\\3- Devoirs\\HW1_2025\\assignment1_release\\test.py\", line 76, in test_forward\n",
      "    model = MLP(self.input_size, self.hidden_sizes, self.output_size)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\OneDrive - Universite de Montreal\\Documents\\1-UNIVERSITE DE MONTREAL\\1-COURS\\3- Hiver 2025\\1- IFT6135 - Representation Learning\\3- Devoirs\\HW1_2025\\assignment1_release\\mlp.py\", line 50, in __init__\n",
      "    self.hidden_layers, self.output_layer = self._build_layers(self.input_size, self.hidden_sizes, self.num_classes)\n",
      "                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\OneDrive - Universite de Montreal\\Documents\\1-UNIVERSITE DE MONTREAL\\1-COURS\\3- Hiver 2025\\1- IFT6135 - Representation Learning\\3- Devoirs\\HW1_2025\\assignment1_release\\mlp.py\", line 75, in _build_layers\n",
      "    hidden_layers.append(self.activation_fn(self.activation, hidden_layer))\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\OneDrive - Universite de Montreal\\Documents\\1-UNIVERSITE DE MONTREAL\\1-COURS\\3- Hiver 2025\\1- IFT6135 - Representation Learning\\3- Devoirs\\HW1_2025\\assignment1_release\\mlp.py\", line 86, in activation_fn\n",
      "    return activation(inputs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: 'str' object is not callable\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_mlp (test.TestMLP.test_mlp)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\maciu\\OneDrive - Universite de Montreal\\Documents\\1-UNIVERSITE DE MONTREAL\\1-COURS\\3- Hiver 2025\\1- IFT6135 - Representation Learning\\3- Devoirs\\HW1_2025\\assignment1_release\\test.py\", line 49, in test_mlp\n",
      "    model = MLP(self.input_size, self.hidden_sizes, self.output_size)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\OneDrive - Universite de Montreal\\Documents\\1-UNIVERSITE DE MONTREAL\\1-COURS\\3- Hiver 2025\\1- IFT6135 - Representation Learning\\3- Devoirs\\HW1_2025\\assignment1_release\\mlp.py\", line 50, in __init__\n",
      "    self.hidden_layers, self.output_layer = self._build_layers(self.input_size, self.hidden_sizes, self.num_classes)\n",
      "                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\OneDrive - Universite de Montreal\\Documents\\1-UNIVERSITE DE MONTREAL\\1-COURS\\3- Hiver 2025\\1- IFT6135 - Representation Learning\\3- Devoirs\\HW1_2025\\assignment1_release\\mlp.py\", line 75, in _build_layers\n",
      "    hidden_layers.append(self.activation_fn(self.activation, hidden_layer))\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\OneDrive - Universite de Montreal\\Documents\\1-UNIVERSITE DE MONTREAL\\1-COURS\\3- Hiver 2025\\1- IFT6135 - Representation Learning\\3- Devoirs\\HW1_2025\\assignment1_release\\mlp.py\", line 86, in activation_fn\n",
      "    return activation(inputs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "TypeError: 'str' object is not callable\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_mlpmixer (test.TestMLPMixer.test_mlpmixer)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\maciu\\OneDrive - Universite de Montreal\\Documents\\1-UNIVERSITE DE MONTREAL\\1-COURS\\3- Hiver 2025\\1- IFT6135 - Representation Learning\\3- Devoirs\\HW1_2025\\assignment1_release\\test.py\", line 145, in test_mlpmixer\n",
      "    outputs = model(inputs)\n",
      "              ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\OneDrive - Universite de Montreal\\Documents\\1-UNIVERSITE DE MONTREAL\\1-COURS\\3- Hiver 2025\\1- IFT6135 - Representation Learning\\3- Devoirs\\HW1_2025\\assignment1_release\\mlpmixer.py\", line 117, in forward\n",
      "    out = self.blocks(out)\n",
      "          ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\container.py\", line 250, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\OneDrive - Universite de Montreal\\Documents\\1-UNIVERSITE DE MONTREAL\\1-COURS\\3- Hiver 2025\\1- IFT6135 - Representation Learning\\3- Devoirs\\HW1_2025\\assignment1_release\\mlpmixer.py\", line 76, in forward\n",
      "    x += self.mlp_tokens(self.norm1(x).transpose(1, 2)).transpose(1, 2)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\OneDrive - Universite de Montreal\\Documents\\1-UNIVERSITE DE MONTREAL\\1-COURS\\3- Hiver 2025\\1- IFT6135 - Representation Learning\\3- Devoirs\\HW1_2025\\assignment1_release\\mlpmixer.py\", line 52, in forward\n",
      "    x = self.fc1(x)\n",
      "        ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (5120x256 and 64x256)\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_basic_block2 (test.TestResNet.test_basic_block2)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\maciu\\OneDrive - Universite de Montreal\\Documents\\1-UNIVERSITE DE MONTREAL\\1-COURS\\3- Hiver 2025\\1- IFT6135 - Representation Learning\\3- Devoirs\\HW1_2025\\assignment1_release\\test.py\", line 97, in test_basic_block2\n",
      "    outputs = block(inputs)\n",
      "              ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\OneDrive - Universite de Montreal\\Documents\\1-UNIVERSITE DE MONTREAL\\1-COURS\\3- Hiver 2025\\1- IFT6135 - Representation Learning\\3- Devoirs\\HW1_2025\\assignment1_release\\resnet18.py\", line 45, in forward\n",
      "    out += self.shortcut(out)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\container.py\", line 250, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 554, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 549, in _conv_forward\n",
      "    return F.conv2d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: Given groups=1, weight of size [128, 64, 1, 1], expected input[32, 128, 8, 8] to have 64 channels, but got 128 channels instead\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_resnet (test.TestResNet.test_resnet)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\maciu\\OneDrive - Universite de Montreal\\Documents\\1-UNIVERSITE DE MONTREAL\\1-COURS\\3- Hiver 2025\\1- IFT6135 - Representation Learning\\3- Devoirs\\HW1_2025\\assignment1_release\\test.py\", line 107, in test_resnet\n",
      "    logits = model(inputs)\n",
      "             ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\OneDrive - Universite de Montreal\\Documents\\1-UNIVERSITE DE MONTREAL\\1-COURS\\3- Hiver 2025\\1- IFT6135 - Representation Learning\\3- Devoirs\\HW1_2025\\assignment1_release\\resnet18.py\", line 71, in forward\n",
      "    out = self.layer4(self.layer3(self.layer2(self.layer1(out))))\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\container.py\", line 250, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\OneDrive - Universite de Montreal\\Documents\\1-UNIVERSITE DE MONTREAL\\1-COURS\\3- Hiver 2025\\1- IFT6135 - Representation Learning\\3- Devoirs\\HW1_2025\\assignment1_release\\resnet18.py\", line 45, in forward\n",
      "    out += self.shortcut(out)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\container.py\", line 250, in forward\n",
      "    input = module(input)\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1736, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1747, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 554, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\maciu\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 549, in _conv_forward\n",
      "    return F.conv2d(\n",
      "           ^^^^^^^^^\n",
      "RuntimeError: Given groups=1, weight of size [128, 64, 1, 1], expected input[50, 128, 16, 16] to have 64 channels, but got 128 channels instead\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_patch_emb (test.TestMLPMixer.test_patch_emb)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\maciu\\OneDrive - Universite de Montreal\\Documents\\1-UNIVERSITE DE MONTREAL\\1-COURS\\3- Hiver 2025\\1- IFT6135 - Representation Learning\\3- Devoirs\\HW1_2025\\assignment1_release\\test.py\", line 124, in test_patch_emb\n",
      "    assert out.shape[1] == mod.num_patches\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 12 tests in 0.642s\n",
      "\n",
      "FAILED (failures=1, errors=6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=12 errors=6 failures=1>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "import test\n",
    "suite = unittest.TestLoader().loadTestsFromModule(test)\n",
    "unittest.TextTestRunner(verbosity=2).run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-PtvL_yKp3PW"
   },
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iWiJme7XaLiR"
   },
   "source": [
    "Below we define a few default arguments to get you started with your experiments. You are encouraged to modify the function `main_entry()`, as well as these arguments, to fit your needs (e.g. changing hyperparameters, the optimizer, adding regularizations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YUrqebfCobD1"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Arguments:\n",
    "  # Data\n",
    "  batch_size: int = 128\n",
    "  # Model\n",
    "  model: str = 'mlp'  # [mlp, resnet18, mlpmixer]\n",
    "  model_config: str = \"./model_configs/mlp.json\" # path to model config json file\n",
    "\n",
    "  # Optimization\n",
    "  optimizer: str = 'adamw'  # [sgd, momentum, adam, adamw]\n",
    "  epochs: int = 15\n",
    "  lr: float = 1e-3\n",
    "  momentum: float = 0.9\n",
    "  weight_decay: float = 5e-4\n",
    "\n",
    "  # Experiment\n",
    "  logdir: str = '/content/assignment/logs'\n",
    "  seed: int = 42\n",
    "\n",
    "  # Miscellaneous\n",
    "  device: str = 'cuda'\n",
    "  visualize : bool = False\n",
    "  print_every: int = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "g2rjoY-5phTY"
   },
   "outputs": [],
   "source": [
    "# Main code entry. Train the model and save the logs\n",
    "from main import train, evaluate\n",
    "def main_entry(args):\n",
    "    # Check for the device\n",
    "    if (args.device == \"cuda\") and not torch.cuda.is_available():\n",
    "        warnings.warn(\n",
    "            \"CUDA is not available, make that your environment is \"\n",
    "            \"running on GPU (e.g. in the Notebook Settings in Google Colab). \"\n",
    "            'Forcing device=\"cpu\".'\n",
    "        )\n",
    "        args.device = \"cpu\"\n",
    "\n",
    "    if args.device == \"cpu\":\n",
    "        warnings.warn(\n",
    "            \"You are about to run on CPU, and might run out of memory \"\n",
    "            \"shortly. You can try setting batch_size=1 to reduce memory usage.\"\n",
    "        )\n",
    "\n",
    "    # Seed the experiment, for repeatability\n",
    "    seed_experiment(args.seed)\n",
    "\n",
    "    test_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                     transforms.Normalize([0.49139968, 0.48215841, 0.44653091], [0.24703223, 0.24348513, 0.26158784])\n",
    "                                     ])\n",
    "    # For training, we add some augmentation. Networks are too powerful and would overfit.\n",
    "    train_transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.RandomResizedCrop((32,32),scale=(0.8,1.0),ratio=(0.9,1.1)),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.49139968, 0.48215841, 0.44653091], [0.24703223, 0.24348513, 0.26158784])\n",
    "                                        ])\n",
    "    # Loading the training dataset. We need to split it into a training and validation part\n",
    "    # We need to do a little trick because the validation set should not use the augmentation.\n",
    "    train_dataset = CIFAR10(root='./data', train=True, transform=train_transform, download=True)\n",
    "    val_dataset = CIFAR10(root='./data', train=True, transform=test_transform, download=True)\n",
    "    train_set, _ = torch.utils.data.random_split(train_dataset, [45000, 5000])\n",
    "    _, val_set = torch.utils.data.random_split(val_dataset, [45000, 5000])\n",
    "\n",
    "    # Loading the test set\n",
    "    test_set = CIFAR10(root='./data', train=False, transform=test_transform, download=True)\n",
    "    \n",
    "    # Load model\n",
    "    print(f'Build model {args.model.upper()}...')\n",
    "    if args.model_config is not None:\n",
    "        print(f'Loading model config from {args.model_config}')\n",
    "        with open(args.model_config) as f:\n",
    "            model_config = json.load(f)\n",
    "    else:\n",
    "        raise ValueError('Please provide a model config json')\n",
    "    print(f'########## {args.model.upper()} CONFIG ################')\n",
    "    for key, val in model_config.items():\n",
    "        print(f'{key}:\\t{val}')\n",
    "    print('############################################')\n",
    "    model_cls = {'mlp': MLP, 'resnet18': ResNet18, 'mlpmixer': MLPMixer}[args.model]\n",
    "    model = model_cls(**model_config)\n",
    "    model.to(args.device)\n",
    "    \n",
    "    # Optimizer\n",
    "    if args.optimizer == \"adamw\":\n",
    "        optimizer = optim.AdamW(\n",
    "            model.parameters(), lr=args.lr, weight_decay=args.weight_decay\n",
    "        )\n",
    "    elif args.optimizer == \"adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "    elif args.optimizer == \"sgd\":\n",
    "        optimizer = optim.SGD(\n",
    "            model.parameters(), lr=args.lr, weight_decay=args.weight_decay\n",
    "        )\n",
    "    elif args.optimizer == \"momentum\":\n",
    "        optimizer = optim.SGD(\n",
    "            model.parameters(),\n",
    "            lr=args.lr,\n",
    "            momentum=args.momentum,\n",
    "            weight_decay=args.weight_decay,\n",
    "        )\n",
    "    \n",
    "    print(\n",
    "        f\"Initialized {args.model.upper()} model with {sum(p.numel() for p in model.parameters())} \"\n",
    "        f\"total parameters, of which {sum(p.numel() for p in model.parameters() if p.requires_grad)} are learnable.\"\n",
    "    )\n",
    "\n",
    "    train_losses, valid_losses = [], []\n",
    "    train_accs, valid_accs = [], []\n",
    "    train_times, valid_times = [], []\n",
    "    \n",
    "    # We define a set of data loaders that we can use for various purposes later.\n",
    "    train_dataloader = DataLoader(train_set, batch_size=args.batch_size, shuffle=True, drop_last=True, pin_memory=True, num_workers=4)\n",
    "    valid_dataloader = DataLoader(val_set, batch_size=args.batch_size, shuffle=False, drop_last=False, num_workers=4)\n",
    "    test_dataloader = DataLoader(test_set, batch_size=args.batch_size, shuffle=False, drop_last=False, num_workers=4)\n",
    "    for epoch in range(args.epochs):\n",
    "        tqdm.write(f\"====== Epoch {epoch} ======>\")\n",
    "        loss, acc, wall_time = train(epoch, model, train_dataloader, optimizer,args)\n",
    "        train_losses.append(loss)\n",
    "        train_accs.append(acc)\n",
    "        train_times.append(wall_time)\n",
    "\n",
    "        loss, acc, wall_time = evaluate(epoch, model, valid_dataloader,args)\n",
    "        valid_losses.append(loss)\n",
    "        valid_accs.append(acc)\n",
    "        valid_times.append(wall_time)\n",
    "\n",
    "    test_loss, test_acc, test_time = evaluate(\n",
    "        epoch, model, test_dataloader, args, mode=\"test\"\n",
    "    )\n",
    "    print(f\"===== Best validation Accuracy: {max(valid_accs):.3f} =====>\")\n",
    "\n",
    "    # Save log if logdir provided\n",
    "    if args.logdir is not None:\n",
    "        print(f'Writing training logs to {args.logdir}...')\n",
    "        os.makedirs(args.logdir, exist_ok=True)\n",
    "        with open(os.path.join(args.logdir, 'results.json'), 'w') as f:\n",
    "            f.write(json.dumps(\n",
    "                {\n",
    "                    \"train_losses\": train_losses,\n",
    "                    \"valid_losses\": valid_losses,\n",
    "                    \"train_accs\": train_accs,\n",
    "                    \"valid_accs\": valid_accs,\n",
    "                    \"test_loss\": test_loss,\n",
    "                    \"test_acc\": test_acc\n",
    "                },\n",
    "                indent=4,\n",
    "            ))\n",
    "    \n",
    "        # Visualize\n",
    "        if args.visualize and args.model in ['resnet18', 'mlpmixer']:\n",
    "            model.visualize(args.logdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZyJPWO1ppcTx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maciu\\AppData\\Local\\Temp\\ipykernel_6972\\812909305.py:6: UserWarning: CUDA is not available, make that your environment is running on GPU (e.g. in the Notebook Settings in Google Colab). Forcing device=\"cpu\".\n",
      "  warnings.warn(\n",
      "C:\\Users\\maciu\\AppData\\Local\\Temp\\ipykernel_6972\\812909305.py:14: UserWarning: You are about to run on CPU, and might run out of memory shortly. You can try setting batch_size=1 to reduce memory usage.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "URLError",
     "evalue": "<urlopen error [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond>",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTimeoutError\u001B[0m                              Traceback (most recent call last)",
      "File \u001B[1;32m~\\miniconda3\\envs\\ift6758-conda-env\\Lib\\urllib\\request.py:1344\u001B[0m, in \u001B[0;36mAbstractHTTPHandler.do_open\u001B[1;34m(self, http_class, req, **http_conn_args)\u001B[0m\n\u001B[0;32m   1343\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1344\u001B[0m     h\u001B[38;5;241m.\u001B[39mrequest(req\u001B[38;5;241m.\u001B[39mget_method(), req\u001B[38;5;241m.\u001B[39mselector, req\u001B[38;5;241m.\u001B[39mdata, headers,\n\u001B[0;32m   1345\u001B[0m               encode_chunked\u001B[38;5;241m=\u001B[39mreq\u001B[38;5;241m.\u001B[39mhas_header(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTransfer-encoding\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[0;32m   1346\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err: \u001B[38;5;66;03m# timeout error\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ift6758-conda-env\\Lib\\http\\client.py:1336\u001B[0m, in \u001B[0;36mHTTPConnection.request\u001B[1;34m(self, method, url, body, headers, encode_chunked)\u001B[0m\n\u001B[0;32m   1335\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1336\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ift6758-conda-env\\Lib\\http\\client.py:1382\u001B[0m, in \u001B[0;36mHTTPConnection._send_request\u001B[1;34m(self, method, url, body, headers, encode_chunked)\u001B[0m\n\u001B[0;32m   1381\u001B[0m     body \u001B[38;5;241m=\u001B[39m _encode(body, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbody\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m-> 1382\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mendheaders(body, encode_chunked\u001B[38;5;241m=\u001B[39mencode_chunked)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ift6758-conda-env\\Lib\\http\\client.py:1331\u001B[0m, in \u001B[0;36mHTTPConnection.endheaders\u001B[1;34m(self, message_body, encode_chunked)\u001B[0m\n\u001B[0;32m   1330\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CannotSendHeader()\n\u001B[1;32m-> 1331\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_send_output(message_body, encode_chunked\u001B[38;5;241m=\u001B[39mencode_chunked)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ift6758-conda-env\\Lib\\http\\client.py:1091\u001B[0m, in \u001B[0;36mHTTPConnection._send_output\u001B[1;34m(self, message_body, encode_chunked)\u001B[0m\n\u001B[0;32m   1090\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_buffer[:]\n\u001B[1;32m-> 1091\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msend(msg)\n\u001B[0;32m   1093\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m message_body \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1094\u001B[0m \n\u001B[0;32m   1095\u001B[0m     \u001B[38;5;66;03m# create a consistent interface to message_body\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ift6758-conda-env\\Lib\\http\\client.py:1035\u001B[0m, in \u001B[0;36mHTTPConnection.send\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m   1034\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_open:\n\u001B[1;32m-> 1035\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconnect()\n\u001B[0;32m   1036\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ift6758-conda-env\\Lib\\http\\client.py:1470\u001B[0m, in \u001B[0;36mHTTPSConnection.connect\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1468\u001B[0m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConnect to a host on a given (SSL) port.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1470\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mconnect()\n\u001B[0;32m   1472\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tunnel_host:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ift6758-conda-env\\Lib\\http\\client.py:1001\u001B[0m, in \u001B[0;36mHTTPConnection.connect\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1000\u001B[0m sys\u001B[38;5;241m.\u001B[39maudit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttp.client.connect\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhost, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mport)\n\u001B[1;32m-> 1001\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msock \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_connection(\n\u001B[0;32m   1002\u001B[0m     (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhost,\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mport), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msource_address)\n\u001B[0;32m   1003\u001B[0m \u001B[38;5;66;03m# Might fail in OSs that don't implement TCP_NODELAY\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ift6758-conda-env\\Lib\\socket.py:865\u001B[0m, in \u001B[0;36mcreate_connection\u001B[1;34m(address, timeout, source_address, all_errors)\u001B[0m\n\u001B[0;32m    864\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m all_errors:\n\u001B[1;32m--> 865\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exceptions[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    866\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m ExceptionGroup(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcreate_connection failed\u001B[39m\u001B[38;5;124m\"\u001B[39m, exceptions)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ift6758-conda-env\\Lib\\socket.py:850\u001B[0m, in \u001B[0;36mcreate_connection\u001B[1;34m(address, timeout, source_address, all_errors)\u001B[0m\n\u001B[0;32m    849\u001B[0m     sock\u001B[38;5;241m.\u001B[39mbind(source_address)\n\u001B[1;32m--> 850\u001B[0m sock\u001B[38;5;241m.\u001B[39mconnect(sa)\n\u001B[0;32m    851\u001B[0m \u001B[38;5;66;03m# Break explicitly a reference cycle\u001B[39;00m\n",
      "\u001B[1;31mTimeoutError\u001B[0m: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mURLError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 5\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Example to run MLP with 15 epochs\u001B[39;00m\n\u001B[0;32m      2\u001B[0m config \u001B[38;5;241m=\u001B[39m Arguments(model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmlp\u001B[39m\u001B[38;5;124m'\u001B[39m, \n\u001B[0;32m      3\u001B[0m                    model_config\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124massignment/model_configs/mlp.json\u001B[39m\u001B[38;5;124m'\u001B[39m, \n\u001B[0;32m      4\u001B[0m                    epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, logdir\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexps/mlp_default\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 5\u001B[0m main_entry(config)\n",
      "Cell \u001B[1;32mIn[8], line 33\u001B[0m, in \u001B[0;36mmain_entry\u001B[1;34m(args)\u001B[0m\n\u001B[0;32m     26\u001B[0m train_transform \u001B[38;5;241m=\u001B[39m transforms\u001B[38;5;241m.\u001B[39mCompose([transforms\u001B[38;5;241m.\u001B[39mRandomHorizontalFlip(),\n\u001B[0;32m     27\u001B[0m                                       transforms\u001B[38;5;241m.\u001B[39mRandomResizedCrop((\u001B[38;5;241m32\u001B[39m,\u001B[38;5;241m32\u001B[39m),scale\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m0.8\u001B[39m,\u001B[38;5;241m1.0\u001B[39m),ratio\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m0.9\u001B[39m,\u001B[38;5;241m1.1\u001B[39m)),\n\u001B[0;32m     28\u001B[0m                                       transforms\u001B[38;5;241m.\u001B[39mToTensor(),\n\u001B[0;32m     29\u001B[0m                                       transforms\u001B[38;5;241m.\u001B[39mNormalize([\u001B[38;5;241m0.49139968\u001B[39m, \u001B[38;5;241m0.48215841\u001B[39m, \u001B[38;5;241m0.44653091\u001B[39m], [\u001B[38;5;241m0.24703223\u001B[39m, \u001B[38;5;241m0.24348513\u001B[39m, \u001B[38;5;241m0.26158784\u001B[39m])\n\u001B[0;32m     30\u001B[0m                                     ])\n\u001B[0;32m     31\u001B[0m \u001B[38;5;66;03m# Loading the training dataset. We need to split it into a training and validation part\u001B[39;00m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;66;03m# We need to do a little trick because the validation set should not use the augmentation.\u001B[39;00m\n\u001B[1;32m---> 33\u001B[0m train_dataset \u001B[38;5;241m=\u001B[39m CIFAR10(root\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./data\u001B[39m\u001B[38;5;124m'\u001B[39m, train\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, transform\u001B[38;5;241m=\u001B[39mtrain_transform, download\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     34\u001B[0m val_dataset \u001B[38;5;241m=\u001B[39m CIFAR10(root\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./data\u001B[39m\u001B[38;5;124m'\u001B[39m, train\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, transform\u001B[38;5;241m=\u001B[39mtest_transform, download\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     35\u001B[0m train_set, _ \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mrandom_split(train_dataset, [\u001B[38;5;241m45000\u001B[39m, \u001B[38;5;241m5000\u001B[39m])\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torchvision\\datasets\\cifar.py:66\u001B[0m, in \u001B[0;36mCIFAR10.__init__\u001B[1;34m(self, root, train, transform, target_transform, download)\u001B[0m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain \u001B[38;5;241m=\u001B[39m train  \u001B[38;5;66;03m# training set or test set\u001B[39;00m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m download:\n\u001B[1;32m---> 66\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdownload()\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_integrity():\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset not found or corrupted. You can use download=True to download it\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torchvision\\datasets\\cifar.py:140\u001B[0m, in \u001B[0;36mCIFAR10.download\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    138\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFiles already downloaded and verified\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    139\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m--> 140\u001B[0m download_and_extract_archive(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39murl, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroot, filename\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfilename, md5\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtgz_md5)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torchvision\\datasets\\utils.py:395\u001B[0m, in \u001B[0;36mdownload_and_extract_archive\u001B[1;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001B[0m\n\u001B[0;32m    392\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m filename:\n\u001B[0;32m    393\u001B[0m     filename \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mbasename(url)\n\u001B[1;32m--> 395\u001B[0m download_url(url, download_root, filename, md5)\n\u001B[0;32m    397\u001B[0m archive \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(download_root, filename)\n\u001B[0;32m    398\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExtracting \u001B[39m\u001B[38;5;132;01m{\u001B[39;00marchive\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mextract_root\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torchvision\\datasets\\utils.py:122\u001B[0m, in \u001B[0;36mdownload_url\u001B[1;34m(url, root, filename, md5, max_redirect_hops)\u001B[0m\n\u001B[0;32m    119\u001B[0m     _download_file_from_remote_location(fpath, url)\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;66;03m# expand redirect chain if needed\u001B[39;00m\n\u001B[1;32m--> 122\u001B[0m     url \u001B[38;5;241m=\u001B[39m _get_redirect_url(url, max_hops\u001B[38;5;241m=\u001B[39mmax_redirect_hops)\n\u001B[0;32m    124\u001B[0m     \u001B[38;5;66;03m# check if file is located on Google Drive\u001B[39;00m\n\u001B[0;32m    125\u001B[0m     file_id \u001B[38;5;241m=\u001B[39m _get_google_drive_file_id(url)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ift6758-conda-env\\Lib\\site-packages\\torchvision\\datasets\\utils.py:66\u001B[0m, in \u001B[0;36m_get_redirect_url\u001B[1;34m(url, max_hops)\u001B[0m\n\u001B[0;32m     63\u001B[0m headers \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMethod\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHEAD\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUser-Agent\u001B[39m\u001B[38;5;124m\"\u001B[39m: USER_AGENT}\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(max_hops \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m---> 66\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m urllib\u001B[38;5;241m.\u001B[39mrequest\u001B[38;5;241m.\u001B[39murlopen(urllib\u001B[38;5;241m.\u001B[39mrequest\u001B[38;5;241m.\u001B[39mRequest(url, headers\u001B[38;5;241m=\u001B[39mheaders)) \u001B[38;5;28;01mas\u001B[39;00m response:\n\u001B[0;32m     67\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m response\u001B[38;5;241m.\u001B[39murl \u001B[38;5;241m==\u001B[39m url \u001B[38;5;129;01mor\u001B[39;00m response\u001B[38;5;241m.\u001B[39murl \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     68\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m url\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ift6758-conda-env\\Lib\\urllib\\request.py:215\u001B[0m, in \u001B[0;36murlopen\u001B[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001B[0m\n\u001B[0;32m    213\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    214\u001B[0m     opener \u001B[38;5;241m=\u001B[39m _opener\n\u001B[1;32m--> 215\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m opener\u001B[38;5;241m.\u001B[39mopen(url, data, timeout)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ift6758-conda-env\\Lib\\urllib\\request.py:515\u001B[0m, in \u001B[0;36mOpenerDirector.open\u001B[1;34m(self, fullurl, data, timeout)\u001B[0m\n\u001B[0;32m    512\u001B[0m     req \u001B[38;5;241m=\u001B[39m meth(req)\n\u001B[0;32m    514\u001B[0m sys\u001B[38;5;241m.\u001B[39maudit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124murllib.Request\u001B[39m\u001B[38;5;124m'\u001B[39m, req\u001B[38;5;241m.\u001B[39mfull_url, req\u001B[38;5;241m.\u001B[39mdata, req\u001B[38;5;241m.\u001B[39mheaders, req\u001B[38;5;241m.\u001B[39mget_method())\n\u001B[1;32m--> 515\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_open(req, data)\n\u001B[0;32m    517\u001B[0m \u001B[38;5;66;03m# post-process response\u001B[39;00m\n\u001B[0;32m    518\u001B[0m meth_name \u001B[38;5;241m=\u001B[39m protocol\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_response\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ift6758-conda-env\\Lib\\urllib\\request.py:532\u001B[0m, in \u001B[0;36mOpenerDirector._open\u001B[1;34m(self, req, data)\u001B[0m\n\u001B[0;32m    529\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n\u001B[0;32m    531\u001B[0m protocol \u001B[38;5;241m=\u001B[39m req\u001B[38;5;241m.\u001B[39mtype\n\u001B[1;32m--> 532\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_chain(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle_open, protocol, protocol \u001B[38;5;241m+\u001B[39m\n\u001B[0;32m    533\u001B[0m                           \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_open\u001B[39m\u001B[38;5;124m'\u001B[39m, req)\n\u001B[0;32m    534\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result:\n\u001B[0;32m    535\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ift6758-conda-env\\Lib\\urllib\\request.py:492\u001B[0m, in \u001B[0;36mOpenerDirector._call_chain\u001B[1;34m(self, chain, kind, meth_name, *args)\u001B[0m\n\u001B[0;32m    490\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m handler \u001B[38;5;129;01min\u001B[39;00m handlers:\n\u001B[0;32m    491\u001B[0m     func \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(handler, meth_name)\n\u001B[1;32m--> 492\u001B[0m     result \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs)\n\u001B[0;32m    493\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    494\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ift6758-conda-env\\Lib\\urllib\\request.py:1392\u001B[0m, in \u001B[0;36mHTTPSHandler.https_open\u001B[1;34m(self, req)\u001B[0m\n\u001B[0;32m   1391\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhttps_open\u001B[39m(\u001B[38;5;28mself\u001B[39m, req):\n\u001B[1;32m-> 1392\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdo_open(http\u001B[38;5;241m.\u001B[39mclient\u001B[38;5;241m.\u001B[39mHTTPSConnection, req,\n\u001B[0;32m   1393\u001B[0m                         context\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_context)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ift6758-conda-env\\Lib\\urllib\\request.py:1347\u001B[0m, in \u001B[0;36mAbstractHTTPHandler.do_open\u001B[1;34m(self, http_class, req, **http_conn_args)\u001B[0m\n\u001B[0;32m   1344\u001B[0m         h\u001B[38;5;241m.\u001B[39mrequest(req\u001B[38;5;241m.\u001B[39mget_method(), req\u001B[38;5;241m.\u001B[39mselector, req\u001B[38;5;241m.\u001B[39mdata, headers,\n\u001B[0;32m   1345\u001B[0m                   encode_chunked\u001B[38;5;241m=\u001B[39mreq\u001B[38;5;241m.\u001B[39mhas_header(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTransfer-encoding\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[0;32m   1346\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err: \u001B[38;5;66;03m# timeout error\u001B[39;00m\n\u001B[1;32m-> 1347\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m URLError(err)\n\u001B[0;32m   1348\u001B[0m     r \u001B[38;5;241m=\u001B[39m h\u001B[38;5;241m.\u001B[39mgetresponse()\n\u001B[0;32m   1349\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n",
      "\u001B[1;31mURLError\u001B[0m: <urlopen error [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond>"
     ]
    }
   ],
   "source": [
    "# Example to run MLP with 15 epochs\n",
    "# config = Arguments(model='mlp',\n",
    "#                    model_config='./model_configs/mlp.json',\n",
    "#                    epochs=15,\n",
    "#                    logdir=\"exps/mlp_default\")\n",
    "\n",
    "for nl in ['relu', 'sigmoid', 'tanh']:\n",
    "    config = Arguments(model='mlp',\n",
    "                       model_config=f'./model_configs/mlp/mlp_{nl}.json',\n",
    "                       epochs=15,\n",
    "                       logdir=f'exps/mlp/mlp_{nl}')\n",
    "    main_entry(config)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from utils import generate_plots\n",
    "list_of_dirs = [f'exps/mlp/mlp_{nl}' for nl in ['relu', 'sigmoid', 'tanh']]\n",
    "legend_names = ['ReLU', 'Sigmoid', 'Tanh']\n",
    "\n",
    "save_fig_path = os.makedirs('results', exist_ok=True)\n",
    "\n",
    "generate_plots(list_of_dirs, legend_names, 'results')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "ift6758-conda-env",
   "language": "python",
   "name": "ift6758-conda-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "81c564fb939afe7b3f114d194e01dc23538f9aaa81b9a9b61cd5d8751a87bdce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
